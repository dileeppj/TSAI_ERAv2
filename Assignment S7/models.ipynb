{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 \n",
    "* Target:\n",
    "    - Set Basic Working Code\n",
    "    - Set Transforms\n",
    "    - Add Batch-norm to increase model efficiency\n",
    "* Results:\n",
    "    - Parameters: 11,212\n",
    "    - Best Training Accuracy: 99.81%\n",
    "    - Best Test Accuracy: 99.34%\n",
    "* Analysis:\n",
    "    - Heavy Model for such a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # Input Block\n",
    "        # Convolution Block\n",
    "        self.convBlock1 = nn.Sequential(\n",
    "            # Convolution 1                     28x28x1 -> 28x28x8  -> RF 3\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            # Convolution 2                     28x28x8 -> 26x26x16 -> RF 5\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.transBlock1 = nn.Sequential(\n",
    "            # Transition 1                      26x26x16 -> 13x13x8 -> RF 7\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock2 = nn.Sequential(\n",
    "            # Convolution 3                    13x13x8 -> 13x13x16  -> RF 11\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Convolution 4                    13x13x16 -> 11x11x32 -> RF 15\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.transBlock2 = nn.Sequential(\n",
    "            # Transition 2                      11x11x32 -> 5x5x32  -> RF 19\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock3 = nn.Sequential(\n",
    "            # Convolution 3                     5x5x16   -> 3x3x16  -> RF 27\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            # Convolution 4                     3x3x16   -> 3x3x10  -> RF 27\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "        # Output Block\n",
    "        self.convBlock4 = nn.Sequential(\n",
    "            # Convolution 5                     3x3x10   -> 1x1x10  -> RF 35\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convBlock1(x)\n",
    "        x = self.transBlock1(x)\n",
    "        x = self.convBlock2(x)\n",
    "        x = self.transBlock2(x)\n",
    "        x = self.convBlock3(x)\n",
    "        x = self.convBlock4(x)\n",
    "        x = x.view(-1, 10) #1x1x10> 10\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2\n",
    "* Target:\n",
    "    - Add Regularization, Dropout\n",
    "    - Increase model capacity. Add more layers at the end. \n",
    "* Results:\n",
    "    - Parameters: 7,400\n",
    "    - Best Training Accuracy: 98.71%\n",
    "    - Best Test Accuracy: 99.15%\n",
    "* Analysis:\n",
    "    - Able to reduce the model size less than 8000 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.1\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # Input Block\n",
    "        # Convolution Block\n",
    "        self.convBlock1 = nn.Sequential(\n",
    "            # Convolution 1                     28x28x1 -> 28x28x8  -> RF 3\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 2                     28x28x8 -> 26x26x16  -> RF 5\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.transBlock1 = nn.Sequential(\n",
    "            # Transition 1                      26x26x16 -> 13x13x8  -> RF 7\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock2 = nn.Sequential(\n",
    "            # Convolution 3                    13x13x8 -> 13x13x16  -> RF 11\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 4                    13x13x16 -> 11x11x16  -> RF 15\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.convBlock3 = nn.Sequential(\n",
    "            # Transition 2                      11x11x16 -> 5x5x10    -> RF 19\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock4 = nn.Sequential(\n",
    "            # Convolution 3                     5x5x10   -> 3x3x16    -> RF 27\n",
    "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 4                     3x3x16   -> 3x3x8   -> RF 27\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "        # Output Block\n",
    "        self.convBlock5 = nn.Sequential(\n",
    "            # Convolution 5                     3x3x8   -> 1x1x10    -> RF 35\n",
    "            nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convBlock1(x)\n",
    "        x = self.transBlock1(x)\n",
    "        x = self.convBlock2(x)\n",
    "        x = self.convBlock3(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.convBlock4(x)\n",
    "        x = self.convBlock5(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3\n",
    "* Target:\n",
    "    - Add rotation, we guess that 5-7 degrees should be sufficient. \n",
    "    - Add LR Scheduler\n",
    "* Results:\n",
    "    - Parameters: 7,400\n",
    "    - Best Training Accuracy: 98.73%\n",
    "    - Best Test Accuracy: 99.24%\n",
    "* Analysis:\n",
    "    - Need to acheive 99.4% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_value = 0.1\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # Input Block\n",
    "        # Convolution Block\n",
    "        self.convBlock1 = nn.Sequential(\n",
    "            # Convolution 1                     28x28x1 -> 28x28x8  -> RF 3\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 2                     28x28x8 -> 26x26x16  -> RF 5\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.transBlock1 = nn.Sequential(\n",
    "            # Transition 1                      26x26x16 -> 13x13x8  -> RF 7\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock2 = nn.Sequential(\n",
    "            # Convolution 3                    13x13x8 -> 13x13x16  -> RF 11\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 4                    13x13x16 -> 11x11x16  -> RF 15\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value)\n",
    "        )\n",
    "        # Transition Block\n",
    "        self.convBlock3 = nn.Sequential(\n",
    "            # Transition 2                      11x11x16 -> 5x5x10    -> RF 19\n",
    "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "        self.gap = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Convolution Block\n",
    "        self.convBlock4 = nn.Sequential(\n",
    "            # Convolution 3                     5x5x10   -> 3x3x16    -> RF 27\n",
    "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_value),\n",
    "            # Convolution 4                     3x3x16   -> 3x3x8   -> RF 27\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
    "        )\n",
    "        # Output Block\n",
    "        self.convBlock5 = nn.Sequential(\n",
    "            # Convolution 5                     3x3x8   -> 1x1x10    -> RF 35\n",
    "            nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), padding=0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convBlock1(x)\n",
    "        x = self.transBlock1(x)\n",
    "        x = self.convBlock2(x)\n",
    "        x = self.convBlock3(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.convBlock4(x)\n",
    "        x = self.convBlock5(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
